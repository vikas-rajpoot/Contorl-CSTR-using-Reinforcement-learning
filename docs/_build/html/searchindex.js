Search.setIndex({"docnames": ["DDPG", "buffer", "env", "index", "main", "matrics", "modules", "ploting", "random_sa", "simulator", "test_trained_agent", "utils"], "filenames": ["DDPG.rst", "buffer.rst", "env.rst", "index.rst", "main.rst", "matrics.rst", "modules.rst", "ploting.rst", "random_sa.rst", "simulator.rst", "test_trained_agent.rst", "utils.rst"], "titles": ["DDPG module", "buffer module", "env module", "Stable-Baselines3 Docs - Reliable Reinforcement Learning Implementations", "main module", "matrics module", "RL_1", "ploting module", "random_sa module", "simulator module", "test_trained_agent module", "utils module"], "terms": {"class": [0, 1, 2, 3], "actor": [0, 6, 10], "state_dim": [0, 1], "action_dim": [0, 1], "sourc": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11], "base": [0, 1, 2], "forward": [0, 6], "state": [0, 1, 2, 7, 10, 11], "defin": [0, 2], "comput": [], "perform": 3, "everi": [], "call": 2, "should": [], "overridden": [], "all": 3, "subclass": [], "although": [], "recip": [], "pass": 0, "need": [0, 7], "within": 2, "thi": [0, 2, 11], "function": [0, 2, 3, 7, 10, 11], "one": 2, "instanc": [], "afterward": [], "instead": [], "sinc": [], "former": [], "take": [0, 2, 11], "care": [], "run": [4, 6], "regist": [], "hook": [], "while": [], "latter": [], "silent": [], "ignor": [], "them": 11, "critic": [0, 6], "action": [0, 1, 2, 7, 10, 11], "discount": 0, "0": 0, "99": 0, "tau": 0, "001": 0, "object": [0, 1], "load": [0, 6], "dir": 0, "ep": 0, "save": [0, 6, 7, 10], "select_act": [0, 6], "train": [0, 3, 6, 10], "replay_buff": [0, 4], "batch_siz": [0, 1, 4], "256": 0, "replaybuff": [0, 1, 6], "max_siz": 1, "1000000": 1, "add": [1, 6], "next_stat": 1, "reward": [1, 2], "done": [1, 2], "sampl": [0, 1, 6], "save_buff": [1, 6], "cstr_env": [2, 6], "calculate_error": [2, 6], "calculate_integral_error": [2, 6], "calculate_reward": [2, 6], "x_next": 2, "u_curr": 2, "u_prev": 2, "initial_sa": [2, 6], "is_don": [2, 6], "reset": [2, 6], "environ": 0, "an": [], "initi": 2, "return": [0, 2, 7, 11], "observ": [0, 2, 11], "note": [], "": 7, "random": [], "number": 0, "gener": [], "variabl": [], "independ": [], "between": 2, "multipl": [], "In": [], "other": [], "word": [], "each": [2, 3, 11], "yield": [], "suitabl": [], "new": [], "episod": [0, 2], "previou": 2, "type": [3, 11], "save_episode_data": [2, 6], "setpoint": [2, 6], "step": [2, 6], "s_action": 2, "timestep": [], "dynam": [], "when": 2, "end": [], "i": [0, 2, 3, 7, 10, 11], "reach": [], "you": [], "ar": [0, 2], "respons": [], "accept": [], "tupl": [], "info": [], "paramet": 11, "provid": 3, "agent": [0, 2, 3, 10, 11], "current": 2, "float": [], "amount": [], "after": [], "bool": [], "whether": [], "ha": [], "which": [0, 10], "case": [], "further": [], "undefin": [], "result": 3, "dict": [], "contain": [], "auxiliari": [], "diagnost": [], "inform": [], "help": [], "debug": [], "sometim": [], "learn": 7, "rl_1": 3, "ddpg": [3, 6], "modul": [3, 6], "buffer": [0, 3, 6], "env": [3, 4, 6], "main": 6, "matric": [3, 6], "plote": [3, 6], "random_sa": [3, 6], "simul": [3, 6, 7], "test_trained_ag": [3, 6], "util": [3, 6], "index": 3, "search": 3, "page": 3, "polici": 4, "start_timestep": 4, "total_ep_train": 4, "plot_seri": [5, 6], "seri": 5, "titl": 5, "xlabel": 5, "ylabel": 5, "file": [5, 7], "world": [], "cup": [], "held": [], "octob": [], "we": 0, "try": [], "plai": [], "differ": [], "wai": [], "give": [0, 2], "peopl": [], "freedom": [], "think": [], "have": [], "win": [], "match": [], "been": [], "import": [], "event": [], "thing": [], "happen": [], "so": [], "obvious": [], "do": 0, "our": [], "messag": [], "focu": [], "someth": [], "india": [], "coach": [], "rahul": [], "dravid": [], "speak": [], "star": [], "sport": [], "game": [], "felt": [], "wasn": [], "t": 2, "469": [], "wicket": [], "bowl": [], "first": [], "coupl": [], "session": [], "dai": [], "1": [2, 11], "came": [], "back": [], "bite": [], "But": [], "rohit": [], "experienc": [], "batter": [], "side": [], "who": [], "england": [], "befor": [], "couldn": [], "quit": [], "stand": [], "up": [], "cost": [], "plot_sliding_mean": [5, 6], "data": [0, 5, 10], "window": 5, "titil": 5, "plot_mpc_rl_comparis": [6, 7], "plot_rl_comparis": [6, 7], "plot_xu": [6, 7], "sample_act": [6, 8], "sample_st": [6, 8], "cstr_dynam": [6, 9], "closed_loop_simulation_rl": [6, 10], "clip_act": [6, 11], "normalize_minmax_act": [6, 11], "normalize_minmax_error": [6, 11], "normalize_minmax_ierror": [6, 11], "normalize_minmax_st": [6, 11], "reverse_normalize_minmax_act": [6, 11], "reverse_normalize_minmax_error": [6, 11], "reverse_normalize_minmax_ierror": [6, 11], "reverse_normalize_minmax_st": [6, 11], "rl_xk": 7, "rl_uk": 7, "mpc_xk": 7, "mpc_uk": 7, "itr": 7, "us": [0, 2, 7, 10, 11], "plot": [3, 7, 10], "four": [7, 11], "c_a": [2, 7, 11], "c_b": [2, 7, 11], "t_r": [2, 7, 11], "t_k": [2, 7, 11], "two": [7, 11], "f": [7, 9, 11], "dot": [7, 11], "q": [0, 7, 11], "np": [7, 11], "ndarrai": [7, 11], "numpi": 7, "arrai": [0, 2, 7, 11], "content": 7, "close": 7, "loop": 7, "reinforc": 7, "mpc": 7, "control": 7, "integ": [0, 7], "uniqu": 7, "kei": 7, "given": [7, 11], "figur": 7, "str": [0, 7], "path": 7, "where": [0, 7], "none": [0, 7], "argument": [0, 2, 7], "ti": 9, "tf": 9, "y01": 9, "y02": 9, "y03": 9, "y04": 9, "q_dot": 9, "test": [3, 10], "rl": [3, 10, 11], "network": [0, 10], "folder": 10, "model": [0, 10], "It": [2, 3, 10], "test_data": 10, "test_plot": 10, "scale": 11, "rescal": 11, "x": 11, "convert": 11, "rang": 11, "x_scale": 11, "list": 11, "valu": [0, 2, 11], "origin": 11, "input": [0, 11], "revers": 11, "transform": 11, "from": [0, 11], "actual": 11, "error": [2, 11], "minmax": 11, "integr": [2, 11], "sb3": 3, "set": [2, 3], "algorithm": [0, 3], "pytorch": 3, "next": [2, 3], "major": 3, "version": 3, "baselin": 3, "github": 3, "repositori": 3, "http": 3, "com": 3, "dlr": 3, "rm": 3, "paper": 3, "jmlr": 3, "org": 3, "volume22": 3, "20": 3, "1364": 3, "pdf": 3, "zoo": 3, "framework": [0, 3], "collect": 3, "pre": 3, "script": 3, "evalu": 3, "tune": 3, "hyperparamet": 3, "record": 3, "video": 3, "contrib": 3, "experiment": 3, "code": 3, "latest": 3, "team": 3, "unifi": 3, "structur": [0, 3], "pep8": 3, "compliant": 3, "style": 3, "document": 3, "high": 3, "coverag": 3, "hint": 3, "clean": 3, "tensorboard": 3, "support": 3, "The": 3, "wa": 3, "see": 3, "section": 3, "respect": 3, "To": [], "project": [], "public": [], "articl": [], "author": [], "antonin": [], "raffin": [], "ashlei": [], "hill": [], "adam": [], "gleav": [], "anssi": [], "kanervisto": [], "maximilian": [], "ernestu": [], "noah": [], "dormann": [], "journal": [], "machin": [], "research": [], "year": [], "2021": [], "volum": [], "22": [], "268": [], "8": [], "url": [], "v22": [], "html": [], "ani": [], "interest": [], "make": [], "better": [], "still": [], "some": [], "improv": [], "can": [], "check": 2, "issu": [], "repo": [], "If": [], "want": [], "pleas": [], "read": [], "md": [], "neural": 0, "part": 0, "predict": 0, "its": 0, "arguement": 0, "output": 0, "loss": 0, "directori": 0, "taken": 0, "updat": 0, "replai": 0, "interact": 0, "store": 0, "randomli": 0, "select": 0, "default": 0, "actor_train": [4, 6], "calcul": 2, "vector": 2, "refer": 2, "c_": 2, "A": 2, "ref": 2, "b": 2, "t_": 2, "r": 2, "k": 2, "precess": 2, "funtion": 2, "s_t": 2, "time": 2, "instant": 2, "a_t": 2, "instatn": 2, "steadi": 2, "process": 2, "condit": 2, "e": 2, "weather": 2, "last": 2, "five": 2, "consecut": 2, "epsilon": 2, "start": 2, "goal": 2}, "objects": {"": [[0, 0, 0, "-", "DDPG"], [11, 0, 0, "-", "argparse_actions"], [1, 0, 0, "-", "buffer"], [2, 0, 0, "-", "env"], [4, 0, 0, "-", "main"], [5, 0, 0, "-", "matrics"], [7, 0, 0, "-", "ploting"], [8, 0, 0, "-", "random_sa"], [9, 0, 0, "-", "simulator"], [10, 0, 0, "-", "test_trained_agent"], [11, 0, 0, "-", "utils"]], "DDPG": [[0, 1, 1, "", "Actor"], [0, 1, 1, "", "Critic"], [0, 1, 1, "", "DDPG"]], "DDPG.Actor": [[0, 2, 1, "", "forward"]], "DDPG.Critic": [[0, 2, 1, "", "forward"]], "DDPG.DDPG": [[0, 2, 1, "", "load"], [0, 2, 1, "", "save"], [0, 2, 1, "", "select_action"], [0, 2, 1, "", "train"]], "buffer": [[1, 1, 1, "", "ReplayBuffer"]], "buffer.ReplayBuffer": [[1, 2, 1, "", "add"], [1, 2, 1, "", "sample"], [1, 2, 1, "", "save_buffer"]], "env": [[2, 1, 1, "", "cstr_env"]], "env.cstr_env": [[2, 2, 1, "", "calculate_errors"], [2, 2, 1, "", "calculate_integral_errors"], [2, 2, 1, "", "calculate_reward"], [2, 2, 1, "", "initial_sa"], [2, 2, 1, "", "is_done"], [2, 2, 1, "", "reset"], [2, 2, 1, "", "save_episode_data"], [2, 2, 1, "", "setpoint"], [2, 2, 1, "", "step"]], "main": [[4, 3, 1, "", "actor_training"], [4, 3, 1, "", "run"]], "matrics": [[5, 3, 1, "", "plot_series"], [5, 3, 1, "", "plot_sliding_mean"]], "ploting": [[7, 3, 1, "", "plot_mpc_rl_comparision"], [7, 3, 1, "", "plot_rl_comparision"], [7, 3, 1, "", "plot_xu"]], "random_sa": [[8, 3, 1, "", "sample_actions"], [8, 3, 1, "", "sample_states"]], "simulator": [[9, 3, 1, "", "cstr_dynamics"]], "test_trained_agent": [[10, 3, 1, "", "closed_loop_simulation_rl"]], "utils": [[11, 3, 1, "", "clip_actions"], [11, 3, 1, "", "normalize_minmax_actions"], [11, 3, 1, "", "normalize_minmax_error"], [11, 3, 1, "", "normalize_minmax_ierror"], [11, 3, 1, "", "normalize_minmax_states"], [11, 3, 1, "", "reverse_normalize_minmax_actions"], [11, 3, 1, "", "reverse_normalize_minmax_error"], [11, 3, 1, "", "reverse_normalize_minmax_ierror"], [11, 3, 1, "", "reverse_normalize_minmax_states"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "function", "Python function"]}, "titleterms": {"ddpg": 0, "modul": [0, 1, 2, 4, 5, 7, 8, 9, 10, 11], "buffer": 1, "env": 2, "welcom": [], "vk": [], "": [], "document": [], "content": [], "indic": [], "tabl": [], "main": [3, 4], "matric": 5, "rl_1": 6, "plote": 7, "random_sa": 8, "simul": 9, "test_trained_ag": 10, "util": 11, "stabl": 3, "baselines3": 3, "doc": 3, "reliabl": 3, "reinforc": 3, "learn": 3, "implement": 3, "featur": 3, "cite": [], "contribut": [], "user": 3, "guid": 3, "rl": [], "algorithm": []}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"DDPG module": [[0, "module-DDPG"]], "buffer module": [[1, "module-buffer"]], "env module": [[2, "module-env"]], "Stable-Baselines3 Docs - Reliable Reinforcement Learning Implementations": [[3, "stable-baselines3-docs-reliable-reinforcement-learning-implementations"]], "Main Features": [[3, "main-features"]], "User Guide": [[3, null]], "main module": [[4, "module-main"]], "matrics module": [[5, "module-matrics"]], "RL_1": [[6, "rl-1"]], "ploting module": [[7, "module-ploting"]], "random_sa module": [[8, "module-random_sa"]], "simulator module": [[9, "module-simulator"]], "test_trained_agent module": [[10, "module-test_trained_agent"]], "utils module": [[11, "module-utils"]]}, "indexentries": {"actor (class in ddpg)": [[0, "DDPG.Actor"]], "critic (class in ddpg)": [[0, "DDPG.Critic"]], "ddpg": [[0, "module-DDPG"]], "ddpg (class in ddpg)": [[0, "DDPG.DDPG"]], "forward() (ddpg.actor method)": [[0, "DDPG.Actor.forward"]], "forward() (ddpg.critic method)": [[0, "DDPG.Critic.forward"]], "load() (ddpg.ddpg method)": [[0, "DDPG.DDPG.load"]], "module": [[0, "module-DDPG"], [1, "module-buffer"], [2, "module-env"], [4, "module-main"], [5, "module-matrics"], [7, "module-ploting"], [8, "module-random_sa"], [9, "module-simulator"], [10, "module-test_trained_agent"], [11, "module-argparse_actions"], [11, "module-utils"]], "save() (ddpg.ddpg method)": [[0, "DDPG.DDPG.save"]], "select_action() (ddpg.ddpg method)": [[0, "DDPG.DDPG.select_action"]], "train() (ddpg.ddpg method)": [[0, "DDPG.DDPG.train"]], "replaybuffer (class in buffer)": [[1, "buffer.ReplayBuffer"]], "add() (buffer.replaybuffer method)": [[1, "buffer.ReplayBuffer.add"]], "buffer": [[1, "module-buffer"]], "sample() (buffer.replaybuffer method)": [[1, "buffer.ReplayBuffer.sample"]], "save_buffer() (buffer.replaybuffer method)": [[1, "buffer.ReplayBuffer.save_buffer"]], "calculate_errors() (env.cstr_env method)": [[2, "env.cstr_env.calculate_errors"]], "calculate_integral_errors() (env.cstr_env method)": [[2, "env.cstr_env.calculate_integral_errors"]], "calculate_reward() (env.cstr_env method)": [[2, "env.cstr_env.calculate_reward"]], "cstr_env (class in env)": [[2, "env.cstr_env"]], "env": [[2, "module-env"]], "initial_sa() (env.cstr_env method)": [[2, "env.cstr_env.initial_sa"]], "is_done() (env.cstr_env method)": [[2, "env.cstr_env.is_done"]], "reset() (env.cstr_env method)": [[2, "env.cstr_env.reset"]], "save_episode_data() (env.cstr_env method)": [[2, "env.cstr_env.save_episode_data"]], "setpoint() (env.cstr_env method)": [[2, "env.cstr_env.setpoint"]], "step() (env.cstr_env method)": [[2, "env.cstr_env.step"]], "actor_training() (in module main)": [[4, "main.actor_training"]], "main": [[4, "module-main"]], "run() (in module main)": [[4, "main.run"]], "matrics": [[5, "module-matrics"]], "plot_series() (in module matrics)": [[5, "matrics.plot_series"]], "plot_sliding_mean() (in module matrics)": [[5, "matrics.plot_sliding_mean"]], "plot_mpc_rl_comparision() (in module ploting)": [[7, "ploting.plot_mpc_rl_comparision"]], "plot_rl_comparision() (in module ploting)": [[7, "ploting.plot_rl_comparision"]], "plot_xu() (in module ploting)": [[7, "ploting.plot_xu"]], "ploting": [[7, "module-ploting"]], "random_sa": [[8, "module-random_sa"]], "sample_actions() (in module random_sa)": [[8, "random_sa.sample_actions"]], "sample_states() (in module random_sa)": [[8, "random_sa.sample_states"]], "cstr_dynamics() (in module simulator)": [[9, "simulator.cstr_dynamics"]], "simulator": [[9, "module-simulator"]], "closed_loop_simulation_rl() (in module test_trained_agent)": [[10, "test_trained_agent.closed_loop_simulation_rl"]], "test_trained_agent": [[10, "module-test_trained_agent"]], "argparse_actions": [[11, "module-argparse_actions"]], "clip_actions() (in module utils)": [[11, "utils.clip_actions"]], "normalize_minmax_actions() (in module utils)": [[11, "utils.normalize_minmax_actions"]], "normalize_minmax_error() (in module utils)": [[11, "utils.normalize_minmax_error"]], "normalize_minmax_ierror() (in module utils)": [[11, "utils.normalize_minmax_ierror"]], "normalize_minmax_states() (in module utils)": [[11, "utils.normalize_minmax_states"]], "reverse_normalize_minmax_actions() (in module utils)": [[11, "utils.reverse_normalize_minmax_actions"]], "reverse_normalize_minmax_error() (in module utils)": [[11, "utils.reverse_normalize_minmax_error"]], "reverse_normalize_minmax_ierror() (in module utils)": [[11, "utils.reverse_normalize_minmax_ierror"]], "reverse_normalize_minmax_states() (in module utils)": [[11, "utils.reverse_normalize_minmax_states"]], "utils": [[11, "module-utils"]]}})